import pytz, io, json, os
from datetime import datetime, timedelta, timezone
from astral import LocationInfo
from astral.sun import sun
import re
import base64
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
import numpy as np
import pandas as pd
from datetime import datetime, timedelta, timezone
import logging
from sklearn.metrics import mean_absolute_error, mean_squared_error
import matplotlib.pyplot as plt
from astral import LocationInfo

# scoring funcsì™€ aggregate_metric ìœ í‹¸ í•¨ìˆ˜ë¡œ ë¶„ë¦¬
def get_scoring_funcs():
    return {
        'R2 Score': r2_score,
        'Adjusted R2': lambda y_true, y_pred: adjusted_r2(
            y_true, y_pred,
            y_pred.shape[1] if np.ndim(y_pred) > 1 else 1
        ),
        'MSE': mean_squared_error,
        'MAE': mean_absolute_error,
        'MAPE': mean_absolute_percentage_error,
        'WMAPE': weighted_mean_absolute_percentage_error,
        'SMAPE': symmetric_mean_absolute_percentage_error,
        'CV(RMSE)': coefficient_of_variation_rmse,
        'NMBE': normalized_mean_bias_error,
        'RMSE': rmse,
        'VIF': lambda y_true, y_pred: np.mean(calculate_vif(y_pred)),
    }

def aggregate_metric(func, y_true_arr, y_pred_arr):
    return np.mean([func(y_true_arr[:, j], y_pred_arr[:, j]) for j in range(y_true_arr.shape[1])])

# AI Logger ì„¤ì •
# # ğŸŒ 7ï¸âƒ£ ê²°ê³¼ ì¶œë ¥
# import ace_tools_open as tools
# tools.display_dataframe_to_user(name="Processed Sun Position Data", dataframe=sun_data)

# NumPy íƒ€ì…ì„ Python ë‚´ì¥ íƒ€ì…ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
def convert_numpy(obj):
    if isinstance(obj, np.bool_):
        return bool(obj)  # NumPy bool_ â†’ Python bool ë³€í™˜
    elif isinstance(obj, np.integer):
        return int(obj)  # NumPy int â†’ Python int ë³€í™˜
    elif isinstance(obj, np.floating):
        return float(obj)  # NumPy float â†’ Python float ë³€í™˜
    elif isinstance(obj, np.ndarray):
        return obj.tolist()  # NumPy ë°°ì—´ â†’ Python ë¦¬ìŠ¤íŠ¸ ë³€í™˜
    raise TypeError(f"Object of type {type(obj).__name__} is not JSON serializable")

def calculate_date_range_from_today(min_data_needed: int, lag: int, pred_date=None) -> tuple:
    """
    ì˜¤ëŠ˜ ë‚ ì§œ(00ì‹œ ê¸°ì¤€)ì™€ ìµœì†Œ í•„ìš” ë°ì´í„° ê°œìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ
    ì‹œì‘ ë‚ ì§œ(start_date)ì™€ ì¢…ë£Œ ë‚ ì§œ(end_date)ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜
    
    :param min_data_needed: ìµœì†Œ í•„ìš” ë°ì´í„° ê°œìˆ˜
    :param lag: lag ì°¨ìˆ˜
    :return: (start_date, end_date)
    """
    # ê°™ì€ ìš”ì¼ ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„° ì¼ìˆ˜ë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•´ ì˜¤ëŠ˜ ë‚ ì§œ ê³„ì‚°
    if pred_date is not None:
        # pred_dateê°€ ì£¼ì–´ì§„ ê²½ìš° í•´ë‹¹ ë‚ ì§œë¥¼ ì‚¬ìš©
        today = datetime.strptime(pred_date, "%Y%m%d")
        start_dt = today.replace(hour=0, minute=0, second=0, microsecond=0) - timedelta(days=7 + lag)
    else:
        start_dt = datetime.today().replace(hour=0, minute=0, second=0, microsecond=0) - timedelta(days=7 + lag)
    # ì‹œì‘ ë‚ ì§œ ê³„ì‚°
    end_dt = start_dt + timedelta(days=min_data_needed)
    
    return start_dt.strftime("%Y%m%d"), end_dt.strftime("%Y%m%d")


def filter_data(y_true, y_pred, threshold, percentile):
    """
    ë°ì´í„° í•„í„°ë§ í•¨ìˆ˜: 0ì— ê°€ê¹Œìš´ ê°’ ë° í•˜ìœ„ percentile ì œì™¸.

    Parameters:
        y_true (array-like): ì‹¤ì œ ê°’
        y_pred (array-like): ì˜ˆì¸¡ ê°’
        threshold (float): 0ì— ê°€ê¹Œìš´ ê°’ì„ ì œì™¸í•˜ëŠ” ì ˆëŒ€ ì„ê³„ê°’
        percentile (float): í•˜ìœ„ íŠ¹ì • ë°±ë¶„ìœ¨ì„ ì œì™¸í•˜ëŠ” ê¸°ì¤€

    Returns:
        tuple: (í•„í„°ë§ëœ ì‹¤ì œ ê°’, í•„í„°ë§ëœ ì˜ˆì¸¡ ê°’)
    """
    # âœ… 0ì— ê°€ê¹Œìš´ ê°’ ì œì™¸ (ì ˆëŒ€ ì„ê³„ê°’ ë°©ì‹)
    if threshold is not None:
        valid_indices = y_true > threshold
        y_true_filtered = y_true[valid_indices]
        y_pred_filtered = y_pred[valid_indices]
    else:
        y_true_filtered = y_true
        y_pred_filtered = y_pred

    # âœ… í•˜ìœ„ percentile ê°’ ì œì™¸ (ìë™ ì„ê³„ê°’ ë°©ì‹)
    if percentile is not None and len(y_true_filtered) > 0:
        perc_threshold = np.percentile(y_true_filtered, percentile)
        valid_indices = y_true_filtered > perc_threshold
        y_true_filtered = y_true_filtered[valid_indices]
        y_pred_filtered = y_pred_filtered[valid_indices]

    return y_true_filtered, y_pred_filtered

def mean_absolute_percentage_error(y_true, y_pred, epsilon=1e-8, threshold=1e-3, percentile=None):
    """
    í•„í„°ë§ëœ MAPE (Mean Absolute Percentage Error)ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜.

    Parameters:
        y_true (array-like): ì‹¤ì œ ê°’
        y_pred (array-like): ì˜ˆì¸¡ ê°’
        epsilon (float): 0 ë‚˜ëˆ„ê¸° ë°©ì§€ë¥¼ ìœ„í•œ ì‘ì€ ê°’ (ê¸°ë³¸ê°’: 1e-8)
        threshold (float): 0ì— ê°€ê¹Œìš´ ê°’ì„ ì œì™¸í•˜ëŠ” ì ˆëŒ€ ì„ê³„ê°’ (ê¸°ë³¸ê°’: 0.001, Noneì´ë©´ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
        percentile (float): í•˜ìœ„ íŠ¹ì • ë°±ë¶„ìœ¨ì„ ì œì™¸í•˜ëŠ” ê¸°ì¤€ (ì˜ˆ: 5 â†’ í•˜ìœ„ 5% ê°’ ì œì™¸, ê¸°ë³¸ê°’: None)

    Returns:
        float: í•„í„°ë§ëœ MAPE ê°’ (ì˜ˆì™¸ ë°œìƒ ì‹œ NaN ë°˜í™˜)
    """
    y_true, y_pred = np.array(y_true), np.array(y_pred)

    # ë°ì´í„° í•„í„°ë§
    y_true_filtered, y_pred_filtered = filter_data(y_true, y_pred, threshold, percentile)

    # ëª¨ë“  ê°’ì´ ì œì™¸ëœ ê²½ìš° NaN ë°˜í™˜
    if len(y_true_filtered) == 0:
        return np.nan

    # MAPE ê³„ì‚°
    return np.mean(np.abs((y_true_filtered - y_pred_filtered) / (y_true_filtered + epsilon))) * 100



def weighted_mean_absolute_percentage_error(y_true, y_pred, epsilon=1e-3, threshold=1e-3, percentile=None):
    """
    í•„í„°ë§ëœ WMAPE (Weighted Mean Absolute Percentage Error)ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜.

    Parameters:
        y_true (array-like): ì‹¤ì œ ê°’
        y_pred (array-like): ì˜ˆì¸¡ ê°’
        epsilon (float): 0 ë‚˜ëˆ„ê¸° ë°©ì§€ë¥¼ ìœ„í•œ ì‘ì€ ê°’ (ê¸°ë³¸ê°’: 1e-8)
        threshold (float): 0ì— ê°€ê¹Œìš´ ê°’ì„ ì œì™¸í•˜ëŠ” ì ˆëŒ€ ì„ê³„ê°’ (ê¸°ë³¸ê°’: 0.001, Noneì´ë©´ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
        percentile (float): í•˜ìœ„ íŠ¹ì • ë°±ë¶„ìœ¨ì„ ì œì™¸í•˜ëŠ” ê¸°ì¤€ (ì˜ˆ: 5 â†’ í•˜ìœ„ 5% ê°’ ì œì™¸, ê¸°ë³¸ê°’: None)

    Returns:
        float: í•„í„°ë§ëœ WMAPE ê°’ (ì˜ˆì™¸ ë°œìƒ ì‹œ NaN ë°˜í™˜)
    """
    y_true, y_pred = np.array(y_true), np.array(y_pred)

    # ë°ì´í„° í•„í„°ë§
    y_true_filtered, y_pred_filtered = filter_data(y_true, y_pred, threshold, percentile)

    # ëª¨ë“  ê°’ì´ ì œì™¸ëœ ê²½ìš° NaN ë°˜í™˜
    if len(y_true_filtered) == 0:
        return np.nan

    # WMAPE ê³„ì‚°
    return np.sum(np.abs(y_true_filtered - y_pred_filtered)) / (np.sum(np.abs(y_true_filtered)) + epsilon) * 100

def symmetric_mean_absolute_percentage_error(y_true, y_pred, epsilon=1e-3, threshold=1e-3, percentile=None):
    """
    í•„í„°ë§ëœ SMAPE (Symmetric Mean Absolute Percentage Error)ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜.

    Parameters:
        y_true (array-like): ì‹¤ì œ ê°’
        y_pred (array-like): ì˜ˆì¸¡ ê°’
        epsilon (float): 0 ë‚˜ëˆ„ê¸° ë°©ì§€ë¥¼ ìœ„í•œ ì‘ì€ ê°’ (ê¸°ë³¸ê°’: 1e-8)
        threshold (float): 0ì— ê°€ê¹Œìš´ ê°’ì„ ì œì™¸í•˜ëŠ” ì ˆëŒ€ ì„ê³„ê°’ (ê¸°ë³¸ê°’: 0.001, Noneì´ë©´ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
        percentile (float): í•˜ìœ„ íŠ¹ì • ë°±ë¶„ìœ¨ì„ ì œì™¸í•˜ëŠ” ê¸°ì¤€ (ì˜ˆ: 5 â†’ í•˜ìœ„ 5% ê°’ ì œì™¸, ê¸°ë³¸ê°’: None)

    Returns:
        float: í•„í„°ë§ëœ SMAPE ê°’ (ì˜ˆì™¸ ë°œìƒ ì‹œ NaN ë°˜í™˜)
    """
    y_true, y_pred = np.array(y_true), np.array(y_pred)

    # ë°ì´í„° í•„í„°ë§
    y_true_filtered, y_pred_filtered = filter_data(y_true, y_pred, threshold, percentile)

    # ëª¨ë“  ê°’ì´ ì œì™¸ëœ ê²½ìš° NaN ë°˜í™˜
    if len(y_true_filtered) == 0:
        return np.nan

    # SMAPE ê³„ì‚°
    return np.mean(2 * np.abs(y_true_filtered - y_pred_filtered) /
                   (np.abs(y_true_filtered) + np.abs(y_pred_filtered) + epsilon)) * 100


def coefficient_of_variation_rmse(y_true, y_pred, epsilon=1e-8):
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    mean_y_true = np.mean(y_true)
    return (np.sqrt(mean_squared_error(y_true, y_pred)) / (mean_y_true + epsilon)) * 100

def normalized_mean_bias_error(y_true, y_pred, epsilon=1e-8):
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    mean_y_true = np.mean(y_true)
    return (np.mean(y_pred - y_true) / (mean_y_true + epsilon)) * 100
def evaluate_performance(r2, adj_r2, mse, mae, mape, wmape, smape, cv_rmse, nmbe, rmse, vif):
    return [
        'ë§¤ìš° ìš°ìˆ˜' if r2 > 0.9 else 'ì¢‹ìŒ' if r2 > 0.75 else 'í‰ê· ' if r2 > 0.5 else 'ë‚®ìŒ',
        'ë§¤ìš° ìš°ìˆ˜' if adj_r2 > 0.9 else 'ì¢‹ìŒ' if adj_r2 > 0.75 else 'í‰ê· ' if adj_r2 > 0.5 else 'ë‚®ìŒ',
        'ë§¤ìš° ìš°ìˆ˜' if mse < 10 else 'ì¢‹ìŒ' if mse < 20 else 'í‰ê· ' if mse < 30 else 'ë‚®ìŒ',
        'ë§¤ìš° ìš°ìˆ˜' if mae < 5 else 'ì¢‹ìŒ' if mae < 10 else 'í‰ê· ' if mae < 15 else 'ë‚®ìŒ',
        'ë§¤ìš° ìš°ìˆ˜' if mape < 5 else 'ì¢‹ìŒ' if mape < 10 else 'í‰ê· ' if mape < 20 else 'ë‚®ìŒ',
        'ë§¤ìš° ìš°ìˆ˜' if wmape < 5 else 'ì¢‹ìŒ' if wmape < 10 else 'í‰ê· ' if wmape < 20 else 'ë‚®ìŒ',
        'ë§¤ìš° ìš°ìˆ˜' if smape < 10 else 'ì¢‹ìŒ' if smape < 15 else 'í‰ê· ' if smape < 25 else 'ë‚®ìŒ',
        'ë§¤ìš° ìš°ìˆ˜' if cv_rmse < 5 else 'ì¢‹ìŒ' if cv_rmse < 10 else 'í‰ê· ' if cv_rmse < 20 else 'ë‚®ìŒ',
        'ë§¤ìš° ìš°ìˆ˜' if abs(nmbe) < 5 else 'ì¢‹ìŒ' if abs(nmbe) < 10 else 'í‰ê· ' if abs(nmbe) < 20 else 'ë‚®ìŒ',
        'ë§¤ìš° ìš°ìˆ˜' if rmse < 5 else 'ì¢‹ìŒ' if rmse < 10 else 'í‰ê· ' if rmse < 20 else 'ë‚®ìŒ',
        'ë§¤ìš° ìš°ìˆ˜' if vif < 5 else 'ì¢‹ìŒ' if vif < 10 else 'í‰ê· ' if vif < 20 else 'ë‚®ìŒ'
    ]

def generate_final_conclusion(df_results):
    """
    ì„±ëŠ¥ í‰ê°€ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìµœì¢… ê²°ë¡  ë° ê°œì„  ë°©ì•ˆì„ ì œì‹œí•˜ëŠ” í•¨ìˆ˜
    """
    min_r2 = df_results['R2 Score'].min()
    max_mse = df_results['MSE'].max()
    
    if min_r2 < 0.5 or max_mse > 30:
        conclusion = "ì¼ë¶€ ì¶œë ¥ ì°¨ì›ì˜ ëª¨ë¸ ì„±ëŠ¥ì´ ìµœì í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤."
        recommendations = [
            "1. íŠ¹ì • ì°¨ì›ì˜ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ì„ ê°œì„ í•˜ì„¸ìš”.",
            "2. ê° ì¶œë ¥ ì°¨ì›ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ê°œë³„ì ìœ¼ë¡œ íŠœë‹í•˜ì„¸ìš”.",
            "3. ë³µì¡ì„±ì„ ì¤„ì—¬ ê³¼ì í•©ì„ ë°©ì§€í•˜ì„¸ìš”.",
            "4. ë°ì´í„° ë¶„í¬ë¥¼ í™•ì¸í•˜ê³  ì´ìƒì¹˜ë¥¼ í•´ê²°í•˜ì„¸ìš”.",
        ]
    elif all(df_results['R2 Score'] > 0.75) and all(df_results['MSE'] < 20):
        conclusion = "ëª¨ë¸ ì„±ëŠ¥ì´ ì „ë°˜ì ìœ¼ë¡œ ìš°ìˆ˜í•˜ë©°, ì¶”ê°€ì ì¸ ê°œì„  ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤."
        recommendations = [
            "1. ì¤‘ìš” íŠ¹ì„±ì„ ê²€í† í•˜ê³  ìµœì í™”ë¥¼ ê³ ë ¤í•˜ì„¸ìš”.",
            "2. ì”ì°¨ íŒ¨í„´ì„ í‰ê°€í•˜ì—¬ ì²´ê³„ì ì¸ ì˜¤ë¥˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.",
            "3. ì•™ìƒë¸” ê¸°ë²•ì„ í™œìš©í•˜ì—¬ ì„±ëŠ¥ì„ ë”ìš± í–¥ìƒì‹œí‚¤ì„¸ìš”.",
        ]
    else:
        conclusion = "ëª¨ë¸ ì„±ëŠ¥ì´ ì–‘í˜¸í•˜ë‚˜ ì¼ë¶€ ì¶œë ¥ì—ì„œ ê°œì„ ì˜ ì—¬ì§€ê°€ ìˆìŠµë‹ˆë‹¤."
        recommendations = [
            "1. ë†’ì€ ì˜¤ë¥˜ë¥¼ ë³´ì´ëŠ” ì°¨ì›ì„ ì§‘ì¤‘ì ìœ¼ë¡œ ê°œì„ í•˜ì„¸ìš”.",
            "2. êµì°¨ ê²€ì¦ìœ¼ë¡œ ì¼ë°˜í™” ì„±ëŠ¥ì„ í™•ì¸í•˜ì„¸ìš”.",
            "3. ë‹¤ë¥¸ ì•Œê³ ë¦¬ì¦˜ì„ ì‹¤í—˜í•´ë³´ì„¸ìš”.",
        ]
    
    return conclusion, recommendations

def rmse(y, y_hat):
    return np.sqrt(np.mean((y - y_hat) ** 2))

def nmbe(y, y_hat):
    bias = np.sum(y - y_hat)
    return (bias / (len(y) * np.mean(y))) * 100  # %ë¡œ ë°˜í™˜

def adjusted_r2(y_true, y_pred, num_features):
    n = len(y_true)
    r2 = r2_score(y_true, y_pred)
    return 1 - (1 - r2) * (n - 1) / (n - num_features - 1)

def calculate_vif(X):
    # ë°°ì—´ ì°¨ì› ê²€ì‚¬: 1D ì…ë ¥ì€ 2D í˜•íƒœë¡œ ë³€í™˜
    X = np.array(X)
    if X.ndim == 1:
        X = X.reshape(-1, 1)
    vif_data = []
    for i in range(X.shape[1]):
        X_i = X[:, i]
        X_others = np.delete(X, i, axis=1)
        X_others = np.hstack([np.ones((X_others.shape[0], 1)), X_others])
        beta = np.linalg.inv(X_others.T @ X_others) @ X_others.T @ X_i
        X_i_pred = X_others @ beta
        ss_res = np.sum((X_i - X_i_pred) ** 2)
        ss_tot = np.sum((X_i - np.mean(X_i)) ** 2)
        r_squared = 1 - (ss_res / ss_tot)
        vif = 1 / (1 - r_squared)
        vif_data.append(vif)
    return vif_data

def evaluate_models(y_true, y_preds_base, y_pred_ensemble, column_names=None):
    """
    ë² ì´ìŠ¤ ëª¨ë¸ë“¤ê³¼ ì•™ìƒë¸” ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” í•¨ìˆ˜ (ë‹¤ì°¨ì› ë°ì´í„° ì§€ì›)
    """
    # Ensure y_true is a NumPy array
    if isinstance(y_true, (pd.DataFrame, pd.Series)):
        y_true = y_true.to_numpy()
    if y_true.ndim == 1:
        y_true = y_true.reshape(-1, 1)
    
    y_preds_base = [pred.to_numpy() if isinstance(pred, pd.DataFrame) else pred for pred in y_preds_base]
    y_preds_base = [pred.reshape(-1, 1) if pred.ndim == 1 else pred for pred in y_preds_base]
    
    y_pred_ensemble = y_pred_ensemble.to_numpy() if isinstance(y_pred_ensemble, pd.DataFrame) else y_pred_ensemble
    if y_pred_ensemble.ndim == 1:
        y_pred_ensemble = y_pred_ensemble.reshape(-1, 1)
    
    metrics = ['R2 Score', 'Adjusted R2', 'MSE', 'MAE', 'MAPE', 'WMAPE', 'SMAPE', 'CV(RMSE)', 'NMBE', 'RMSE', 'VIF']
    evaluation_metrics = [metric + ' í‰ê°€' for metric in metrics]

    scoring_funcs = get_scoring_funcs()

    results = []
    evaluations = []

    # ë² ì´ìŠ¤ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
    for i, y_pred in enumerate(y_preds_base):
        vals = [aggregate_metric(func, y_true, y_pred) for func in scoring_funcs.values()]
        results.append([f'Base Model {i+1}'] + vals)
        evaluations.append(evaluate_performance(*vals))

    # ì•™ìƒë¸” ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ì¶”ê°€
    vals = [aggregate_metric(func, y_true, y_pred_ensemble) for func in scoring_funcs.values()]
    results.append([f'Ensemble Model'] + vals)
    evaluations.append(evaluate_performance(*vals))

    # ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ ìƒì„±
    df_results = pd.DataFrame(results, columns=['Model'] + metrics)
    df_evaluations = pd.DataFrame(evaluations, columns=evaluation_metrics)
    df_results = pd.concat([df_results, df_evaluations], axis=1)
    
    conclusion, recommendations = generate_final_conclusion(df_results)
    
    return df_results, conclusion, recommendations


def split_time_series(X_df, y_df, datetime_col="datetime", test_size=0.2):
    """
    DatetimeIndexë¥¼ ê°€ì§„ ë‘ ê°œì˜ ë°ì´í„°í”„ë ˆì„ (X, y)ì„ ë‚ ì§œ(day) ë‹¨ìœ„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ 
    train-test splitì„ ìˆ˜í–‰í•œë‹¤. (shuffle=False)
    
    Parameters:
    - X_df (pd.DataFrame): ë…ë¦½ ë³€ìˆ˜ (í”¼ì²˜ ë°ì´í„°, DatetimeIndex)
    - y_df (pd.DataFrame): ì¢…ì† ë³€ìˆ˜ (íƒ€ê²Ÿ ë°ì´í„°, DatetimeIndex)
    - test_size (float): í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¹„ìœ¨ (ê¸°ë³¸ê°’: 0.2)
    
    Returns:
    - X_train, X_test, y_train, y_test
    """

    # ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ ê·¸ë£¹í™” (DatetimeIndexì˜ ë‚ ì§œ ì¶”ì¶œ)
    X_df["date"] = X_df.index.date
    y_df["date"] = y_df.index.date

    # ê³ ìœ í•œ ë‚ ì§œ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
    unique_dates = X_df["date"].unique()

    # Train-Test ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ ë¶„í• 
    train_size = int(len(unique_dates) * (1 - test_size))
    train_dates = unique_dates[:train_size]
    test_dates = unique_dates[train_size:]

    # ë‚ ì§œ ê¸°ë°˜ ë°ì´í„° ë¶„í• 
    X_train = X_df[X_df["date"].isin(train_dates)].drop(columns=["date"])
    X_test = X_df[X_df["date"].isin(test_dates)].drop(columns=["date"])

    y_train = y_df[y_df["date"].isin(train_dates)].drop(columns=["date"])
    y_test = y_df[y_df["date"].isin(test_dates)].drop(columns=["date"])

    return X_train, X_test, y_train, y_test


def plot_results(y_true, y_pred, model_name, metric_names=None):
    # ê¸¸ì´ ë° ì°¨ì› ë§ì¶”ê¸°
    if isinstance(y_true, pd.DataFrame): y_true = y_true.to_numpy()
    if isinstance(y_pred, pd.DataFrame): y_pred = y_pred.to_numpy()
    # âœ… ê¸¸ì´ ë§ì¶”ê¸° (ì°¨ì› ë³€ê²½ ì—†ì´)
    min_len = min(len(y_true), len(y_pred))
    y_true, y_pred = y_true[:min_len-1], y_pred[:min_len-1]
    if y_true.ndim == 1: y_true = y_true.reshape(-1, 1)
    if y_pred.ndim == 1: y_pred = y_pred.reshape(-1, 1)
    # ì§€í‘œ ê³„ì‚°
    default_names = ['R2 Score', 'MAE', 'RMSE', 'NMBE']
    names = metric_names or default_names
    funcs = get_scoring_funcs()
    metrics_per_dim = {name: [funcs[name](y_true[:, i], y_pred[:, i]) for i in range(y_true.shape[1])] for name in names}
    # ì‹œê°í™”: ì¶œë ¥ ì°¨ì›ë³„
    n_outputs = y_true.shape[1]
    fig, axes = plt.subplots(1, n_outputs, figsize=(6*n_outputs, 6), squeeze=False)
    axes = axes.flatten()
    for i, ax in enumerate(axes):
        ax.plot(y_true[:, i], label='y_true', color='red', alpha=0.7)
        ax.plot(y_pred[:, i], label='y_pred', color='green', linestyle='--', alpha=0.7)
        ax.set_title(f'Output {i+1} ({model_name})')
        ax.set_xlabel('Samples')
        ax.set_ylabel('Value')
        ax.legend()
        ax.grid(True, linestyle='--', alpha=0.6)
        # ì°¨ì›ë³„ ì§€í‘œ overlay
        metric_text = '\n'.join([f"{name}: {metrics_per_dim[name][i]:.2f}" for name in names])
        ax.text(0.02, 0.98, metric_text, transform=ax.transAxes, va='top', fontsize=10, color='black')
    fig.tight_layout()
    # ì´ë¯¸ì§€ ì €ì¥
    image_dir = "/tmp/"
    os.makedirs(image_dir, exist_ok=True)
    image_path = os.path.join(image_dir, "plot.png")
    plt.savefig(image_path, format="png")
    plt.close(fig)
    return image_path

def plot_results_live(y_true, y_pred, model_name, metric_names=None):
    """
    ì‹¤ì œ ê°’ê³¼ ì˜ˆì¸¡ ê°’ì„ ë¹„êµí•˜ëŠ” ê·¸ë˜í”„ë¥¼ ê·¸ë¦¬ëŠ” í•¨ìˆ˜. ë‹¤ì°¨ì› ì¶œë ¥ ë° ì‚¬ìš©ì ì •ì˜ ì§€í‘œ ì§€ì›.
    """
    # ê¸¸ì´ ë° ì°¨ì› ë§ì¶”ê¸°
    if isinstance(y_true, pd.DataFrame): y_true = y_true.to_numpy()
    if isinstance(y_pred, pd.DataFrame): y_pred = y_pred.to_numpy()
    # âœ… ê¸¸ì´ ë§ì¶”ê¸° (ì°¨ì› ë³€ê²½ ì—†ì´)
    min_len = min(len(y_true), len(y_pred))
    y_true, y_pred = y_true[:min_len-1], y_pred[:min_len-1]
    if y_true.ndim == 1: y_true = y_true.reshape(-1, 1)
    if y_pred.ndim == 1: y_pred = y_pred.reshape(-1, 1)
    # ì§€í‘œ ê³„ì‚°
    default_names = ['R2 Score', 'MAE', 'RMSE', 'NMBE']
    names = metric_names or default_names
    funcs = get_scoring_funcs()
    metrics_per_dim = {name: [funcs[name](y_true[:, i], y_pred[:, i]) for i in range(y_true.shape[1])] for name in names}
    # ì‹œê°í™”: ì¶œë ¥ ì°¨ì›ë³„ ë™ì  ìƒì„±
    n_outputs = y_true.shape[1]
    fig, axes = plt.subplots(1, n_outputs, figsize=(6*n_outputs, 6), squeeze=False)
    axes = axes.flatten()
    for i, ax in enumerate(axes):
        ax.plot(y_true[:, i], label='y_true', color='red', alpha=0.7)
        ax.plot(y_pred[:, i], label='y_pred', color='green', linestyle='--', alpha=0.7)
        ax.set_title(f'Output {i+1} ({model_name})')
        ax.set_xlabel('Samples')
        ax.set_ylabel('Value')
        ax.legend()
        ax.grid(True, linestyle='--', alpha=0.6)
        # ì°¨ì›ë³„ ì§€í‘œ í‘œì‹œ
        metric_text = '\n'.join([f"{name}: {metrics_per_dim[name][i]:.2f}" for name in names])
        ax.text(0.02, 0.98, metric_text, transform=ax.transAxes, va='top', fontsize=10, color='black')
    fig.tight_layout()
    # ì´ë¯¸ì§€ ì €ì¥ ë° ë°˜í™˜
    image_dir = '/tmp/'
    os.makedirs(image_dir, exist_ok=True)
    image_path = os.path.join(image_dir, 'plot_live.png')
    plt.savefig(image_path, format='png')
    plt.close(fig)
    return image_path
    
def plot_results_html_content(y_true, y_pred, model_name, metric_names=None):
    """
    ì‹¤ì œ ê°’ê³¼ ì˜ˆì¸¡ ê°’ì„ ë¹„êµí•˜ëŠ” ê·¸ë˜í”„ë¥¼ ê·¸ë¦¬ëŠ” í•¨ìˆ˜ (RÂ², MAE, RMSE í¬í•¨).
    
    Parameters:
        y_true (array-like): ì‹¤ì œ ê°’ (ì¼ì‚¬ëŸ‰, ì „ë ¥ ì†Œë¹„ëŸ‰)
        y_pred (array-like): ì˜ˆì¸¡ ê°’ (ì¼ì‚¬ëŸ‰, ì „ë ¥ ì†Œë¹„ëŸ‰)
        model_name (str): ëª¨ë¸ ì´ë¦„

    Returns:
        str: Base64ë¡œ ì¸ì½”ë”©ëœ HTML ê·¸ë˜í”„ ì´ë¯¸ì§€
    """
    # âœ… ê¸¸ì´ ë§ì¶”ê¸° (ì°¨ì› ë³€ê²½ ì—†ì´)
    min_len = min(len(y_true), len(y_pred))
    y_true = y_true[:min_len-1]
    y_pred = y_pred[:min_len-1]

    # âœ… 1ï¸âƒ£ ë°ì´í„° ë³€í™˜ (DataFrame â†’ NumPy ë³€í™˜)
    if isinstance(y_true, pd.DataFrame):
        y_true = y_true.to_numpy()
    if isinstance(y_pred, pd.DataFrame):
        y_pred = y_pred.to_numpy()

    # âœ… 2ï¸âƒ£ 1ì°¨ì› ë°°ì—´ì„ 2ì°¨ì›ìœ¼ë¡œ ë³€í™˜
    if y_true.ndim == 1:
        y_true = y_true.reshape(-1, 1)
    if y_pred.ndim == 1:
        y_pred = y_pred.reshape(-1, 1)

    # âœ… 3ï¸âƒ£ í‰ê°€ ì§€í‘œ ê³„ì‚° ë° í‰ê· í™” (MAE, RMSE, RÂ², NMBE)
    default_names = ['R2 Score', 'MAE', 'RMSE', 'NMBE']
    names = metric_names or default_names
    funcs = get_scoring_funcs()
    n_outputs = y_true.shape[1]
    metrics_per_dim = {name: [funcs[name](y_true[:, i], y_pred[:, i]) for i in range(n_outputs)] for name in names}
    mae_sunlight, mae_power = metrics_per_dim['MAE']
    rmse_sunlight, rmse_power = metrics_per_dim['RMSE']
    r2_sunlight, r2_power = metrics_per_dim['R2 Score']
    nmbe_sunlight, nmbe_power = metrics_per_dim['NMBE']
    agg_metrics = {name: aggregate_metric(funcs[name], y_true, y_pred) for name in names}

    # âœ… 4ï¸âƒ£ ì‹œê°í™” (ì¶œë ¥ ì°¨ì›ë³„ ë™ì  ì„œë¸Œí”Œë¡¯ ë° ì§€í‘œ í‘œì‹œ)
    fig, axes = plt.subplots(1, n_outputs, figsize=(6*n_outputs, 6), squeeze=False)
    axes = axes.flatten()
    for i, ax in enumerate(axes):
        ax.plot(y_true[:, i], label='y_true', color='red', alpha=0.7)
        ax.plot(y_pred[:, i], label='y_pred', color='green', linestyle='--', alpha=0.7)
        ax.set_title(f'Output {i+1} ({model_name})')
        ax.set_xlabel('Samples')
        ax.set_ylabel('Value')
        ax.legend()
        ax.grid(True, linestyle="--", alpha=0.6)
        # ì°¨ì›ë³„ ì§€í‘œ overlay
        metric_text = '\n'.join([f"{name}: {metrics_per_dim[name][i]:.2f}" for name in names])
        ax.text(0.02, 0.98, metric_text, transform=ax.transAxes, va='top', fontsize=10, color='black')
    fig.tight_layout()
    # í•˜ë‹¨ ì¤‘ì•™ ì „ì²´ í‰ê·  ì§€í‘œ í‘œì‹œ
    agg_text = ', '.join([f"Avg {name}: {agg_metrics[name]:.2f}" for name in names])
    fig.text(0.5, 0.01, agg_text, ha='center', fontsize=10)

    # âœ… 5ï¸âƒ£ ê·¸ë˜í”„ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
    img_buf = io.BytesIO()
    plt.savefig(img_buf, format="png")
    plt.close(fig)  # í”Œë¡¯ì„ ë‹«ì•„ ë©”ëª¨ë¦¬ ì ˆì•½
    img_buf.seek(0)
    
    # âœ… 6ï¸âƒ£ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ Base64ë¡œ ì¸ì½”ë”©
    img_base64 = base64.b64encode(img_buf.getvalue()).decode("utf-8")

    # âœ… 7ï¸âƒ£ HTML ì½”ë“œ ìƒì„±
    html_content = f"""
    <html>
    <head>
        <title>Model Performance</title>
    </head>
    <body>
        <h2>Model: {model_name}</h2>
        <img src="data:image/png;base64,{img_base64}" alt="Generated Plot">
    </body>
    </html>
    """

    return html_content


def plot_html_content(y_true, y_pred, model_name):
    """
    ì‹¤ì œ ê°’ê³¼ ì˜ˆì¸¡ ê°’ì„ ë¹„êµí•˜ëŠ” ê·¸ë˜í”„ë¥¼ ê·¸ë¦¬ëŠ” í•¨ìˆ˜ (RÂ², MAE, RMSE í¬í•¨).
    
    Parameters:
        y_true (array-like): ì‹¤ì œ ê°’ (ì¼ì‚¬ëŸ‰, ì „ë ¥ ì†Œë¹„ëŸ‰)
        y_pred (array-like): ì˜ˆì¸¡ ê°’ (ì¼ì‚¬ëŸ‰, ì „ë ¥ ì†Œë¹„ëŸ‰)
        model_name (str): ëª¨ë¸ ì´ë¦„

    Returns:
        str: Base64ë¡œ ì¸ì½”ë”©ëœ HTML ê·¸ë˜í”„ ì´ë¯¸ì§€
    """
    # âœ… 1ï¸âƒ£ ë°ì´í„° ë³€í™˜ (DataFrame â†’ NumPy ë³€í™˜)
    if isinstance(y_true, pd.DataFrame):
        y_true = y_true.to_numpy()
    if isinstance(y_pred, pd.DataFrame):
        y_pred = y_pred.to_numpy()

    # âœ… 2ï¸âƒ£ 1ì°¨ì› ë°°ì—´ì„ 2ì°¨ì›ìœ¼ë¡œ ë³€í™˜
    if y_true.ndim == 1:
        y_true = y_true.reshape(-1, 1)
    if y_pred.ndim == 1:
        y_pred = y_pred.reshape(-1, 1)


    # âœ… 3ï¸âƒ£ í‰ê°€ ì§€í‘œ ê³„ì‚° ë° í‰ê· í™” (ë™ì )
    names = ['MAE','RMSE','R2 Score','NMBE']
    funcs = get_scoring_funcs()
    n_outputs = y_true.shape[1]
    metrics_per_dim = {name: [funcs[name](y_true[:, i], y_pred[:, i]) for i in range(n_outputs)] for name in names}
    agg_metrics = {name: aggregate_metric(funcs[name], y_true, y_pred) for name in names}
    # âœ… 4ï¸âƒ£ ì‹œê°í™” (ì¶œë ¥ ì°¨ì›ë³„ ë™ì  ì„œë¸Œí”Œë¡¯ ë° ì§€í‘œ í‘œì‹œ)
    fig, axes = plt.subplots(1, n_outputs, figsize=(6*n_outputs, 6), squeeze=False)
    axes = axes.flatten()
    for i, ax in enumerate(axes):
        ax.plot(y_true[:, i], label='y_true', color='red', alpha=0.7)
        ax.plot(y_pred[:, i], label='y_pred', color='green', linestyle='--', alpha=0.7)
        ax.set_title(f'Output {i+1} ({model_name})')
        ax.set_xlabel('Samples')
        ax.set_ylabel('Value')
        ax.legend()
        ax.grid(True, linestyle="--", alpha=0.6)
        metric_text = '\n'.join([f"{name}: {metrics_per_dim[name][i]:.2f}" for name in names])
        ax.text(0.02, 0.98, metric_text, transform=ax.transAxes, va='top', fontsize=10, color='black')
    # âœ… `fig.tight_layout()` ì ìš©
    fig.tight_layout()
    # í•˜ë‹¨ ì¤‘ì•™ ì „ì²´ í‰ê·  ì§€í‘œ í‘œì‹œ
    agg_text = ', '.join([f"Avg {name}: {agg_metrics[name]:.2f}" for name in names])
    fig.text(0.5, 0.01, agg_text, ha='center', fontsize=10)

    # âœ… 5ï¸âƒ£ ê·¸ë˜í”„ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
    img_buf = io.BytesIO()
    plt.savefig(img_buf, format="png")
    plt.close(fig)  # í”Œë¡¯ì„ ë‹«ì•„ ë©”ëª¨ë¦¬ ì ˆì•½
    img_buf.seek(0)
    
    # âœ… 6ï¸âƒ£ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ Base64ë¡œ ì¸ì½”ë”©
    img_base64 = base64.b64encode(img_buf.getvalue()).decode("utf-8")

    # âœ… 7ï¸âƒ£ HTML ì½”ë“œ ìƒì„±
    html_content = f"""
    <html>
    <head>
        <title>Model Performance</title>
    </head>
    <body>
        <h2>Model: {model_name}</h2>
        <img src="data:image/png;base64,{img_base64}" alt="Generated Plot">
    </body>
    </html>
    """

    return html_content


def get_sunrise_sunset(lat, lon, date=None, tz="Asia/Seoul"):
    """
    ì£¼ì–´ì§„ ìœ„ë„(lat), ê²½ë„(lon)ì—ì„œ ì¼ì¶œ ë° ì¼ëª° ì‹œê°„ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ (í•œêµ­ ì‹œê°„ ë³€í™˜).
    
    :param lat: ìœ„ë„
    :param lon: ê²½ë„
    :param date: íŠ¹ì • ë‚ ì§œ (ê¸°ë³¸ê°’: ì˜¤ëŠ˜)
    :param tz: ì‹œê°„ëŒ€ (ê¸°ë³¸ê°’: í•œêµ­ ì‹œê°„ëŒ€ "Asia/Seoul")
    :return: ì¼ì¶œ ë° ì¼ëª° ì‹œê°„ (datetime ê°ì²´, KST ê¸°ì¤€)
    """
    if date is None:
        date = datetime.today()

    location = LocationInfo(latitude=lat, longitude=lon)
    s = sun(location.observer, date=date)

    local_tz = pytz.timezone(tz)  # âœ… pytz ì‚¬ìš©ìœ¼ë¡œ ìˆ˜ì •
    sunrise = s["sunrise"].replace(tzinfo=pytz.utc).astimezone(local_tz)
    sunset = s["sunset"].replace(tzinfo=pytz.utc).astimezone(local_tz)

    return sunrise, sunset


def convert_numpy_types(obj):
    """
    ë„˜íŒŒì´ íƒ€ì…ë“¤ì„ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ ê¸°ë³¸ íƒ€ì…ìœ¼ë¡œ ë³€í™˜
    """
    if isinstance(obj, dict):
        return {k: convert_numpy_types(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [convert_numpy_types(v) for v in obj]
    elif isinstance(obj, np.bool_):
        return bool(obj)
    elif isinstance(obj, (np.integer, np.int32, np.int64)):
        return int(obj)
    elif isinstance(obj, (np.floating, np.float32, np.float64)):
        return float(obj)
    else:
        return obj


def get_latest_trial_path(base_dir, trial_num=None):
    """
    ì§€ì •ëœ ë˜ëŠ” ìµœì‹  trial_ìˆ«ì ê²½ë¡œ ë°˜í™˜
    """
    print(f"base_dir: {base_dir}")
    os.makedirs(base_dir, exist_ok=True)

    if trial_num is not None:
        trial_path = os.path.join(base_dir, f"trial_{trial_num}")
        if not os.path.exists(trial_path):
            raise FileNotFoundError(f"{trial_path} ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return trial_path

    existing_trials = [
        (int(m.group(1)), os.path.join(base_dir, d)) for d in os.listdir(base_dir)
        if (m := re.match(r"trial_(\d+)", d)) and os.path.isdir(os.path.join(base_dir, d))
    ]

    if not existing_trials:
        raise FileNotFoundError("ì €ì¥ëœ trial_í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")
    return max(existing_trials, key=lambda x: x[0])[1]


def get_next_trial_path(base_dir, trial_num=None):
    """
    ì§€ì •ëœ ë˜ëŠ” ìë™ìœ¼ë¡œ ë‹¤ìŒ trial_ìˆ«ì ë””ë ‰í† ë¦¬ ìƒì„±
    """
    os.makedirs(base_dir, exist_ok=True)

    if trial_num is not None:
        trial_path = os.path.join(base_dir, f"trial_{trial_num}")
    else:
        existing_trials = [
            int(m.group(1)) for d in os.listdir(base_dir)
            if (m := re.match(r"trial_(\d+)", d)) and os.path.isdir(os.path.join(base_dir, d))
        ]
        next_num = max(existing_trials, default=0) + 1
        trial_path = os.path.join(base_dir, f"trial_{next_num}")

    os.makedirs(trial_path, exist_ok=True)
    return trial_path


def get_sunrise_sunset(lat, lon, date=None, tz="Asia/Seoul"):
    """
    ì£¼ì–´ì§„ ìœ„ë„(lat), ê²½ë„(lon)ì—ì„œ ì¼ì¶œ ë° ì¼ëª° ì‹œê°„ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ (í•œêµ­ ì‹œê°„ ë³€í™˜).
    
    :param lat: ìœ„ë„
    :param lon: ê²½ë„
    :param date: íŠ¹ì • ë‚ ì§œ (ê¸°ë³¸ê°’: ì˜¤ëŠ˜)
    :param tz: ì‹œê°„ëŒ€ (ê¸°ë³¸ê°’: í•œêµ­ ì‹œê°„ëŒ€ "Asia/Seoul")
    :return: ì¼ì¶œ ë° ì¼ëª° ì‹œê°„ (datetime ê°ì²´, KST ê¸°ì¤€)
    """
    if date is None:
        date = datetime.today()

    location = LocationInfo(latitude=lat, longitude=lon)
    s = sun(location.observer, date=date)

    local_tz = pytz.timezone(tz)  # âœ… pytz ì‚¬ìš©ìœ¼ë¡œ ìˆ˜ì •
    sunrise = s["sunrise"].replace(tzinfo=pytz.utc).astimezone(local_tz)
    sunset = s["sunset"].replace(tzinfo=pytz.utc).astimezone(local_tz)

    return sunrise, sunset

def save_ml_tuning_report(model_name, cleaned_params, metric_score=None, report_dir="./tuning_reports"):
    # 1. ëª¨ë¸ëª… ê¸°ë°˜ ê¸°ë³¸ í´ë”
    base_dir = os.path.join(report_dir, f"{model_name.lower()}_tuning")
    os.makedirs(base_dir, exist_ok=True)  # âœ… ì—†ìœ¼ë©´ ìƒì„±

    # 2. trial_ìˆ«ì í´ë” ëª©ë¡ ì½ê¸°
    existing_trials = [d for d in os.listdir(base_dir) if d.startswith("trial_")]
    existing_trials = [int(d.split('_')[1]) for d in existing_trials if d.split('_')[1].isdigit()]
    next_trial_num = max(existing_trials) + 1 if existing_trials else 0

    # 3. ìƒˆ trial_x í´ë” ìƒì„±
    trial_dir = os.path.join(base_dir, f"trial_{next_trial_num}")
    os.makedirs(trial_dir, exist_ok=True)  # âœ… ì—†ìœ¼ë©´ ìƒì„±
    # 4. trial.json ì €ì¥
    report = {
        "best_params": cleaned_params,
        'metric_score': metric_score if metric_score is not None else {},
    }
    report_path = os.path.join(trial_dir, "trial.json")  # âœ… íŒŒì¼ëª… ê³ ì •

    with open(report_path, "w") as f:
        json.dump(report, f, indent=4)

    print(f"âœ… íŠœë‹ ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ: {report_path}")

def plot_residual_patterns_html_content(y_true, y_pred, model_name, column_names=None):
    """
    ì”ì°¨ íŒ¨í„´ì„ ì‹œê°í™”í•˜ì—¬ HTML ì»¨í…ì¸ ë¡œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜.

    Parameters:
        y_true (array-like): ì‹¤ì œ ê°’.
        y_pred (array-like): ì˜ˆì¸¡ ê°’.
        model_name (str): ëª¨ë¸ ì´ë¦„.
        column_names (list of str, optional): ë‹¤ì¤‘ ì¶œë ¥ ì‹œ ê° ì¶œë ¥ì˜ ì´ë¦„.

    Returns:
        str: Base64ë¡œ ì¸ì½”ë”©ëœ HTML ê·¸ë˜í”„ ì´ë¯¸ì§€.
    """
    # ë°ì´í„° ë³€í™˜ (DataFrame â†’ NumPy ë³€í™˜)
    if isinstance(y_true, pd.DataFrame):
        y_true = y_true.to_numpy()
    if isinstance(y_pred, pd.DataFrame):
        y_pred = y_pred.to_numpy()

    # 1ì°¨ì› ë°°ì—´ì„ 2ì°¨ì›ìœ¼ë¡œ ë³€í™˜
    if y_true.ndim == 1:
        y_true = y_true.reshape(-1, 1)
    if y_pred.ndim == 1:
        y_pred = y_pred.reshape(-1, 1)

    if y_true.shape[1] != y_pred.shape[1]:
        raise ValueError("y_trueì™€ y_predì˜ ì¶œë ¥ íŠ¹ì„± ìˆ˜ê°€ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.")

    num_outputs = y_true.shape[1]
    
    if column_names is None:
        column_names = [f"Output {i+1}" for i in range(num_outputs)]
    elif len(column_names) != num_outputs:
        raise ValueError("column_namesì˜ ê¸¸ì´ì™€ ì¶œë ¥ íŠ¹ì„± ìˆ˜ê°€ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.")

    residuals = y_true - y_pred

    fig, axes = plt.subplots(num_outputs, 2, figsize=(15, 5 * num_outputs), squeeze=False)
    
    for i in range(num_outputs):
        # ì”ì°¨ ëŒ€ ì˜ˆì¸¡ê°’ í”Œë¡¯
        axes[i, 0].scatter(y_pred[:, i], residuals[:, i], alpha=0.5)
        axes[i, 0].axhline(0, color='red', linestyle='--')
        axes[i, 0].set_xlabel(f"Predicted Values ({column_names[i]})")
        axes[i, 0].set_ylabel(f"Residuals ({column_names[i]})")
        axes[i, 0].set_title(f"Residuals vs. Predicted ({column_names[i]})")
        axes[i, 0].grid(True, linestyle="--", alpha=0.6)

        # ì”ì°¨ íˆìŠ¤í† ê·¸ë¨
        axes[i, 1].hist(residuals[:, i], bins=30, alpha=0.7, color='blue')
        axes[i, 1].axvline(residuals[:, i].mean(), color='red', linestyle='--', label=f"Mean: {residuals[:, i].mean():.2f}")
        axes[i, 1].set_xlabel(f"Residuals ({column_names[i]})")
        axes[i, 1].set_ylabel("Frequency")
        axes[i, 1].set_title(f"Histogram of Residuals ({column_names[i]})")
        axes[i, 1].legend()
        axes[i, 1].grid(True, linestyle="--", alpha=0.6)

    fig.suptitle(f"Residual Analysis for {model_name}", fontsize=16, y=1.02 if num_outputs > 1 else 1.05)
    fig.tight_layout(rect=[0, 0, 1, 0.98 if num_outputs > 1 else 0.95]) # Adjust layout to make space for suptitle

    # ê·¸ë˜í”„ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
    img_buf = io.BytesIO()
    plt.savefig(img_buf, format="png")
    plt.close(fig)  # í”Œë¡¯ì„ ë‹«ì•„ ë©”ëª¨ë¦¬ ì ˆì•½
    img_buf.seek(0)
    
    # ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ Base64ë¡œ ì¸ì½”ë”©
    img_base64 = base64.b64encode(img_buf.getvalue()).decode("utf-8")

    # HTML ì½”ë“œ ìƒì„±
    html_content = f"""
    <html>
    <head>
        <title>Residual Analysis: {model_name}</title>
    </head>
    <body>
        <h2>Residual Analysis for Model: {model_name}</h2>
        <img src="data:image/png;base64,{img_base64}" alt="Residual Plots">
    </body>
    </html>
    """
    return html_content

def test_rmse_simple():
    y = np.array([0, 1, 2, 3])
    y_hat = np.array([0, 1, 1, 4])
    expected = np.sqrt(mean_squared_error(y, y_hat))
    return bool(np.isclose(rmse(y, y_hat), expected))

def test_nmbe_zero_bias():
    y = np.array([10, 10, 10])
    y_hat = np.array([10, 10, 10])
    return bool(np.isclose(nmbe(y, y_hat), 0.0))

def test_vif_independent():
    # ë…ë¦½ ë³€ìˆ˜ ë‘ ê°œ
    x1 = np.random.rand(100)
    x2 = np.random.rand(100)
    X = np.column_stack([x1, x2])
    vif = calculate_vif(X)
    # ì„œë¡œ ë…ë¦½ì´ë©´ VIF â‰ˆ 1
    return all(0.9 < v < 1.1 for v in vif)

# ğŸ” ì¶”ê°€ í‰ê°€ì§€í‘œ ê²€ì¦ í…ŒìŠ¤íŠ¸
def test_r2_perfect():
    y = np.array([1, 2, 3, 4])
    y_hat = y.copy()
    func = get_scoring_funcs()['R2 Score']
    return bool(np.isclose(func(y, y_hat), 1.0))

def test_adjusted_r2_perfect():
    y = np.array([1, 2, 3, 4])
    y_hat = y.copy()
    func = get_scoring_funcs()['Adjusted R2']
    # num_features ëª¨ìˆ˜ë¡œ ì¸í•œ ì°¨ì›ì€ ì„ì˜ 1 ì„¤ì •
    return bool(np.isclose(func(y, y_hat), 1.0))

def test_mse_basic():
    y = np.array([0, 1, 2])
    y_hat = np.array([1, 1, 2])
    func = get_scoring_funcs()['MSE']
    expected = mean_squared_error(y, y_hat)
    return bool(np.isclose(func(y, y_hat), expected))

def test_mae_basic():
    y = np.array([0, 1, 2])
    y_hat = np.array([1, 1, 2])
    func = get_scoring_funcs()['MAE']
    expected = mean_absolute_error(y, y_hat)
    return bool(np.isclose(func(y, y_hat), expected))

def test_mape_basic():
    y = np.array([10, 20])
    y_hat = np.array([12, 18])
    func = get_scoring_funcs()['MAPE']
    # (|2/10| + |2/20|)/2*100 = 15
    return bool(np.isclose(func(y, y_hat), 15.0))

def test_wmape_basic():
    y = np.array([10, 20])
    y_hat = np.array([12, 18])
    func = get_scoring_funcs()['WMAPE']
    # WMAPE ê³„ì‚° ì‹œ ë‚´ë¶€ epsilon(1e-3) í¬í•¨
    expected = (np.sum(np.abs(y - y_hat)) / (np.sum(np.abs(y)) + 1e-3)) * 100
    return bool(np.isclose(func(y, y_hat), expected))

def test_smape_basic():
    y = np.array([10, 20])
    y_hat = np.array([12, 18])
    func = get_scoring_funcs()['SMAPE']
    # SMAPE ê³„ì‚° ì‹œ ë‚´ë¶€ epsilon(1e-3) í¬í•¨
    diffs = 2 * np.abs(y - y_hat)
    denoms = np.abs(y) + np.abs(y_hat) + 1e-3
    expected = np.mean(diffs / denoms) * 100
    return bool(np.isclose(func(y, y_hat), expected))

def test_cv_rmse_basic():
    y = np.array([1, 2, 3])
    y_hat = np.array([1, 2, 2])
    func = get_scoring_funcs()['CV(RMSE)']
    # rmse=âˆš(1/3)=0.57735, mean_y=2 â†’ (0.57735/2)*100 â‰ˆ28.8675
    expected = (np.sqrt(mean_squared_error(y, y_hat)) / np.mean(y)) * 100
    return bool(np.isclose(func(y, y_hat), expected))

